{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/breast-cancer-wisconsin-data/data.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport math","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the dataset as a dataframe\nfile_name = '../input/breast-cancer-wisconsin-data/data.csv'\ndata_df = pd.read_csv(file_name)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0  ...          17.33           184.60      2019.0            0.1622   \n1  ...          23.41           158.80      1956.0            0.1238   \n2  ...          25.53           152.50      1709.0            0.1444   \n3  ...          26.50            98.87       567.7            0.2098   \n4  ...          16.67           152.20      1575.0            0.1374   \n\n   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   fractal_dimension_worst  Unnamed: 32  \n0                  0.11890          NaN  \n1                  0.08902          NaN  \n2                  0.08758          NaN  \n3                  0.17300          NaN  \n4                  0.07678          NaN  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 33 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.drop('Unnamed: 32', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['diagnosis'].unique()#.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diagnosis_mapping = {\"M\": 0, \"B\": 1}\n\ndata_df['diagnosis'] = data_df['diagnosis'].map(diagnosis_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'diagnosis', data=data_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,8))\nsns.heatmap(data_df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import SMOTE # Oversampling\nfrom sklearn.metrics import accuracy_score, f1_score, fbeta_score, make_scorer\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nimport re\n\nrandom_state= 101\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_df.drop(['id', 'diagnosis'], axis=1)\ny = data_df['diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = random_state\nfeatures = X_train.columns\nsm = SMOTE(random_state=random_state)#, ratio=1.0)\nX_train, y_train = sm.fit_resample(X_train, y_train)\nX_train = pd.DataFrame(X_train, columns=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = pd.DataFrame(y_train)\na['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Baselining"},{"metadata":{"trusted":true},"cell_type":"code","source":"naive_predictor_accuracy = accuracy_score(y_train,np.ones(len(y_train)))\nnaive_predictor_f1score = f1_score(y_train, np.ones(len(y_train)))\n\nprint(\"Naive predictor accuracy: %.3f\" % (naive_predictor_accuracy))\nprint(\"Naive predictor f1-score: %.3f\" % (naive_predictor_f1score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With Naive predictor baselining model is baselined\n\n# Execute different ML model to find the best fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_performance = []\n\nclassifier_type = [LogisticRegression,\n                    KNeighborsClassifier,\n                    DecisionTreeClassifier,\n                    RandomForestClassifier,\n                    GaussianNB,\n                    SVC, \n                    XGBClassifier]\n\n\ndf = pd.DataFrame(columns=['Model Name', 'Accuracy', 'F1 Score', 'Recall', 'Precision'])\n\nfor mName in classifier_type:\n    model_name = mName\n    model_name = str(model_name)\n    model = mName()\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print(mName,':- ') \n    print(classification_report(y_test,predictions))\n    print('-------------------------------------------------------------')\n    clf_accuracy = accuracy_score(y_test,predictions)\n    clf_f1_score = f1_score(y_test,predictions)\n    clf_recall_score = recall_score(y_test,predictions)\n    clf_precision_score = precision_score(y_test,predictions)\n    \n    #print(\"%s model accuracy-score: %.3f\" % (mName, clf_accuracy))\n    #print(\"%s model f1-score: %.3f\" % (mName, clf_f1_score))\n    #print(\"%s model recall-score: %.3f\" % (mName, clf_recall_score))\n    #print(\"%s model precision-score: %.3f\" % (mName, clf_precision_score))\n    \n    nameLen = len(model_name.split('.'))\n    model_name = model_name.split('.')[nameLen-1]\n    model_name= re.sub('[^A-Za-z0-9]+', '', model_name)\n        \n    df = df.append({'Model Name': model_name, 'Accuracy': clf_accuracy, 'F1 Score': clf_f1_score, 'Recall': clf_recall_score, 'Precision': clf_precision_score }, ignore_index=True)\n\ndf = df.sort_values('Accuracy', ascending=False)\ndf = df.reset_index(drop=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBClassifier model looks to be best fit, lets try some basic modeling "},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = XGBClassifier(max_depth=3, n_estimators=400, learning_rate=0.05).fit(X_train, y_train)\npredictions = gbm.predict(X_test)\n\nprint(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying ML with RandomizedSearchCV - Hyperparameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_xgb = XGBClassifier(objective = 'binary:logistic')\nparam_dist = {'n_estimators': [400],\n              'learning_rate': [.10, .01, .001, .001],\n              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n              'min_child_weight': [1, 2, 3, 4]\n             }\n\nclf = RandomizedSearchCV(clf_xgb, \n                         param_distributions = param_dist,\n                         n_iter = 5, \n                         scoring = 'roc_auc', \n                         error_score = 0, \n                         verbose = 3, \n                         n_jobs = -1)\n\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\nprint(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relative_importance = clf.best_estimator_.feature_importances_\nrelative_importance = relative_importance / np.sum(relative_importance)\n\nfeature_importance =\\\n    pd.DataFrame(list(zip(features,\n                          relative_importance)),\n                 columns=['feature', 'relativeimportance'])\n\nfeature_importance = feature_importance.sort_values('relativeimportance',\n                                                    ascending=False)\n\nfeature_importance = feature_importance.reset_index(drop=True)\n\npalette = sns.color_palette(\"coolwarm\", feature_importance.shape[0])\n\nplt.figure(figsize=(8, 8))\nsns.barplot(x='relativeimportance',\n            y='feature',\n            data=feature_importance,\n            palette=palette)\nplt.xlabel('XGBClassifier')\nplt.ylabel('Feature')\nplt.title('XGBClassifier Estimated Feature Importance')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}